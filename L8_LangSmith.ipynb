{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83b49259",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model calling and intial setup\n",
    "import os\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_openai import AzureChatOpenAI , AzureOpenAIEmbeddings\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser \n",
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") \n",
    "\n",
    "load_dotenv(override= True)\n",
    "# Load env\n",
    "OPENROUTER_API_KEY = os.getenv(\"OPENROUTER_API_KEY\")\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "AZURE_BASE_URL = os.getenv(\"AZURE_BASE_URL\")\n",
    "AZURE_OPENAI_API_KEY = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "AZURE_CHAT_DEPLIOYMENT_NAME = os.getenv(\"AZURE_CHAT_DEPLIOYMENT_NAME\")\n",
    "AZURE_EMBEDDING_DEPLIOYMENT_NAME = os.getenv(\"AZURE_EMBEDDING_DEPLIOYMENT_NAME\")\n",
    "\n",
    "# get all the langsmith based env \n",
    "LANGSMITH_ENDPOINT = os.getenv(\"LANGSMITH_ENDPOINT\")\n",
    "LANGSMITH_TRACING = os.getenv(\"LANGSMITH_TRACING\")\n",
    "LANGSMITH_PROJECT = os.getenv(\"LANGSMITH_PROJECT\")\n",
    "LANGSMITH_API_KEY = os.getenv(\"LANGSMITH_API_KEY\")\n",
    "WEATHERSTACK_API_KEY = os.getenv(\"WEATHERSTACK_API_KEY\")\n",
    "\n",
    "parser = StrOutputParser()\n",
    "\n",
    "llm_gemini = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash-lite\" , api_key= GOOGLE_API_KEY)\n",
    "\n",
    "llm_openai = AzureChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",                         \n",
    "    deployment_name=AZURE_CHAT_DEPLIOYMENT_NAME ,  # deployment name in Azure\n",
    "    api_key=AZURE_OPENAI_API_KEY,\n",
    "    azure_endpoint=AZURE_BASE_URL,\n",
    "    api_version=\"2024-02-01\",\n",
    "    temperature=0.75\n",
    ") \n",
    "\n",
    "embeddings = AzureOpenAIEmbeddings(model=\"text-embedding-3-large\",\n",
    "                             deployment=AZURE_EMBEDDING_DEPLIOYMENT_NAME,\n",
    "                             api_key= AZURE_OPENAI_API_KEY,\n",
    "                             azure_endpoint= AZURE_BASE_URL,\n",
    "                             api_version=\"2024-02-01\"\n",
    "                             )\n",
    "# result = llm_openai.invoke(\"What are your creater, also what type of LLM are you\").content\n",
    "# print(result)\n",
    "# llm_gemini.invoke(\"who is father of india\").content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3d2724",
   "metadata": {},
   "source": [
    "### what need observablity in AI services\n",
    "- can track latency drop\n",
    "- we can log complex llm workflow\n",
    "\n",
    "### Langsmith\n",
    "- use for obersvalibilt and eval platform , where team can deugs and moniter app performace\n",
    "\n",
    "### What langsmith trace\n",
    " - i/p and o/p\n",
    " - all intermediate steps\n",
    " - latency \n",
    " - cost \n",
    " - error \n",
    " - tags \n",
    " - metadata \n",
    " - feedback "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335865a2",
   "metadata": {},
   "source": [
    "## Core Concept\n",
    "1) Project \n",
    "whole project, that is executed mutiple time \n",
    "\n",
    "2) Trace \n",
    "- each time the project is execute it is a trace\n",
    "\n",
    "3) Run\n",
    "- excustion of each trace have mutiple steps, each of the steps is a single run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2e8e212",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(template=\"what is the name of india's first PM?\")\n",
    "chain = prompt | llm_openai | parser\n",
    "result = chain.invoke(input={})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9670407",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"India's first Prime Minister was Jawaharlal Nehru. He served from August 15, 1947, when India gained independence, until his death on May 27, 1964.\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6482bc57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. **AI's Dual Impact on Employment**: The report highlights that while AI in India can enhance productivity and create new job opportunities in sectors like IT and agriculture, it also poses significant risks of job displacement, particularly in manufacturing, customer service, and other routine task-oriented jobs.\n",
      "\n",
      "2. **Current Employment Landscape**: With over 1.4 billion people in India and a workforce of around 500 million, the unemployment rate is approximately 7-8%, with a substantial portion of employment in the informal sector lacking job security and benefits.\n",
      "\n",
      "3. **Job Displacement Risks**: AI-driven automation is leading to significant job losses, especially for roles involving repetitive tasks, while a mismatch in digital skills among the workforce hampers the transition to new jobs created by AI advancements.\n",
      "\n",
      "4. **Opportunity for Job Creation**: AI is generating demand for new roles such as data scientists and machine learning engineers, and fostering entrepreneurship through innovation, which could lead to job creation if supported by adequate upskilling initiatives.\n",
      "\n",
      "5. **Policy Recommendations**: To address the challenges posed by AI, the report suggests implementing nationwide training programs, fostering public-private partnerships for relevant education, creating social safety nets for displaced workers, and establishing innovation hubs to encourage entrepreneurship in tech sectors.\n"
     ]
    }
   ],
   "source": [
    "# from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "prompt1 = PromptTemplate(\n",
    "    template='Generate a detailed report on {topic}',\n",
    "    input_variables=['topic']\n",
    ")\n",
    "prompt2 = PromptTemplate(\n",
    "    template='Generate a 5 pointer summary from the following text \\n {text}',\n",
    "    input_variables=['text']\n",
    ")\n",
    "\n",
    "# This is how one can add project name\n",
    "os.environ['LANGSMITH_PROJECT']= \"Sequential LLM App\"\n",
    "# llm_gemini = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\" , api_key= GOOGLE_API_KEY , temperature=0.9)\n",
    "\n",
    "\n",
    "parser = StrOutputParser()\n",
    "chain = prompt1 | llm_openai | parser | prompt2 | llm_openai | parser\n",
    "\n",
    "config = RunnableConfig(\n",
    "    run_name=\"sequential_report_generation_v1\",\n",
    "    tags=[\"llm_app\", \"report_generation\"]\n",
    ")\n",
    "result = chain.invoke({'topic': 'Role of Ai in unemplyoment in India'} , config= config)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "69dba473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF RAG ready. Ask a question (or Ctrl+C to exit).\n",
      "\n",
      "A: His AWS skills include leveraging serverless AWS architectures to minimize operational costs while ensuring high scalability and security standards.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough, RunnableLambda\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "load_dotenv()  # expects OPENAI_API_KEY in .env\n",
    "\n",
    "PDF_PATH = \"Data\\ShantnuKumar.pdf\"  # <-- change to your PDF filename\n",
    "\n",
    "# 1) Load PDF\n",
    "loader = PyPDFLoader(PDF_PATH)\n",
    "docs = loader.load()  # one Document per page\n",
    "\n",
    "# 2) Chunk\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=150)\n",
    "splits = splitter.split_documents(docs)\n",
    "\n",
    "# 3) Embed + index\n",
    "vs = FAISS.from_documents(splits, embeddings)\n",
    "retriever = vs.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 1})\n",
    "\n",
    "# 4) Prompt\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Answer ONLY from the provided context. If not found, say you don't know.\"),\n",
    "    (\"human\", \"Question: {question}\\n\\nContext:\\n{context}\")\n",
    "])\n",
    "\n",
    "config = RunnableConfig(\n",
    "    run_name=\"rag_example_1\",\n",
    "    tags=[\"llm_app\", \"rag_application\"]\n",
    ")\n",
    "# 5) Chain\n",
    "def format_docs(docs): return \"\\n\\n\".join(d.page_content for d in docs)\n",
    "\n",
    "parallel = RunnableParallel({\n",
    "    \"context\": retriever | RunnableLambda(format_docs),\n",
    "    \"question\": RunnablePassthrough()\n",
    "})\n",
    "\n",
    "chain = parallel | prompt | llm_openai | StrOutputParser()\n",
    "\n",
    "# 6) Ask questions\n",
    "print(\"PDF RAG ready. Ask a question (or Ctrl+C to exit).\")\n",
    "q = input(\"\\nQ: \")\n",
    "ans = chain.invoke(q.strip() ,  config= config)\n",
    "print(\"\\nA:\", ans)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51d89ff",
   "metadata": {},
   "source": [
    "#### Imp Points\n",
    "- By Default only Runnable are tracked by LangSmith, what about the other part like chunkig, loading etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e477a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF RAG ready. Ask a question (or Ctrl+C to exit).\n",
      "\n",
      "A: He managed the full lifecycle for the SpiceReclaim booking forecast model, which included initial development, optimization, and cloud deployment. He improved the accuracy of Payload Prediction models and transitioned them to production environments, ensuring reliable performance using AWS services such as EC2, Lambda, S3, and EventBridge. He also investigated and resolved critical bugs in the Booking Forecast model under pressure, just days before the SpiceReclaim launch.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langsmith import traceable  # <-- key import\n",
    "\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough, RunnableLambda\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "PDF_PATH = \"Data\\ShantnuKumar.pdf\"  # change to your file\n",
    "\n",
    "@traceable(name=\"load_pdf\")\n",
    "def load_pdf(path: str):\n",
    "    loader = PyPDFLoader(path)\n",
    "    return loader.load()  # list[Document]\n",
    "\n",
    "@traceable(name=\"split_documents\" , metadata={\"text_splitter\" : \"RecursiveCharacterTextSplitter\"})\n",
    "def split_documents(docs, chunk_size=1000, chunk_overlap=150):\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size, chunk_overlap=chunk_overlap\n",
    "    )\n",
    "    return splitter.split_documents(docs)\n",
    "\n",
    "@traceable(name=\"build_vectorstore\" , tags=['vectorDB'] , metadata={\"vector_store\" : \"FAISS\" })\n",
    "def build_vectorstore(splits):\n",
    "    # FAISS.from_documents internally calls the embedding model:\n",
    "    vs = FAISS.from_documents(splits, embeddings)\n",
    "    return vs\n",
    "\n",
    "# You can also trace a ‚Äúsetup‚Äù umbrella span if you want:\n",
    "@traceable(name=\"setup_pipeline\")\n",
    "def setup_pipeline(pdf_path: str):\n",
    "    docs = load_pdf(pdf_path)\n",
    "    splits = split_documents(docs)\n",
    "    vs = build_vectorstore(splits)\n",
    "    return vs\n",
    "\n",
    "# ---------- pipeline ----------\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Answer ONLY from the provided context. If not found, say you don't know.\"),\n",
    "    (\"human\", \"Question: {question}\\n\\nContext:\\n{context}\")\n",
    "])\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(d.page_content for d in docs)\n",
    "\n",
    "# Build the index under traced setup\n",
    "vectorstore = setup_pipeline(PDF_PATH)\n",
    "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 4})\n",
    "\n",
    "parallel = RunnableParallel({\n",
    "    \"context\": retriever | RunnableLambda(format_docs),\n",
    "    \"question\": RunnablePassthrough(),\n",
    "})\n",
    "\n",
    "chain = parallel | prompt | llm_openai | StrOutputParser()\n",
    "\n",
    "# ---------- run a query (also traced) ----------\n",
    "print(\"PDF RAG ready. Ask a question (or Ctrl+C to exit).\")\n",
    "q = input(\"\\nQ: \").strip()\n",
    "\n",
    "# Give the visible run name + tags/metadata so it‚Äôs easy to find:\n",
    "config = {\n",
    "    \"run_name\": \"pdf_rag_query\"\n",
    "}\n",
    "\n",
    "ans = chain.invoke(q, config=config)\n",
    "print(\"\\nA:\", ans)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7069db",
   "metadata": {},
   "source": [
    "#### Agent Monitering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb52854f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Indian Army, UP govt help late Army officer's daughter reclaim ancestral home. The Indian Army and Uttar Pradesh government coordinated with civil authorities ... Was gang-rape angle considered in RG Kar case, Calcutta HC asks CBI ¬∑ Nagpur violence: Bulldozers will target more buildings soon, says civic official after ... The Economic Times. Is Archana Puran Singh's son leaving their home? ¬∑ India Today. Who replaces Pakistan if they boycott T20 World Cup 2026 like Bangladesh? Medha Patkar acquitted in defamation case filed by Delhi L-G ¬∑ High Court asks Centre to get video of Manipur man's killing removed ¬∑ Patiala House Court allows ... India Today LIVE TV 24X7 | Headlines | English News LIVE | Latest News ¬∑ India Today TV Live: Minneapolis ICE Shooting | Shashi Tharoor vs Congress | Bangladesh ... Top News ¬∑ Dhanush and Mrunal Thakur tie the knot? Truth behind video revealed ¬∑ Ram Gopal Varma dismisses communal bias claim after AR Rahman's remark ¬∑ Die My ... Delhi court acquits Medha Patkar in defamation case filed by L-G V.K. Saxena ... Union Defence Minister Rajnath Singh felicitated an NCC cadet during his visit to ... Manali Nightmare: 8-km Jam, Hotels 100% Occupied, Tourists Stranded On Road ¬∑ ICC Warns Pakistan With Total Isolation Over T20 World Cup Threats: Sources ... Indian state investigates killings of hundreds of stray dogs. Police say they have confirmed at least 354 killings so far and arrested nine people. 2 days ago. India News Today: Read latest and breaking news headlines from India. Top India News, Current headlines, videos, photos and live india news updates at India\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making our own ai agent\n",
    "from langchain_community.utilities import GoogleSerperAPIWrapper\n",
    "\n",
    "search = GoogleSerperAPIWrapper()\n",
    "search.run(\"Top news in india today\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "12e67037",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a tool out of this \n",
    "from langchain_core.tools import Tool , tool\n",
    "\n",
    "search_tool = Tool(\n",
    "        name=\"Intermediate_Answer\",\n",
    "        func=search.run,\n",
    "        description=\"useful for when you need to ask with search\",\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b2b9cc4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hourly Weather ¬∑ 1 PM 59¬∞. rain drop 0% ¬∑ 2 PM 62¬∞. rain drop 0% ¬∑ 3 PM 64¬∞. rain drop 0% ¬∑ 4 PM 65¬∞. rain drop 0% ¬∑ 5 PM 63¬∞. rain drop 0% ¬∑ 6 PM 61¬∞. rain ... Today. 64¬∞ / 44¬∞. Mostly Sunny. 1%. 8 mph ... Sunny to partly cloudy. Visibility reduced by smoke. High 64F. Winds NW at 5 to 10 mph. ... Overcast. Hazy. Low 44F. New Delhi Extended Forecast with high and low temperatures ... Morning clouds. Feels Like: 65 ¬∞F. Humidity: 42%. Precipitation: Rain: 0 Snow: 0. Current Weather ; RealFeel¬Æ. 50¬∞ ; RealFeel Shade‚Ñ¢. 44¬∞ ; Max UV Index. 3.0 (Moderate) ; Wind. WNW 8 mph ; Wind Gusts. 17 mph. Current New Delhi weather condition is Mist with real-time temperature (12¬∞C), humidity 54%, wind 13.3km/h, pressure (1022mb), UV (0), visibility (5km) in ... Today (Sun, January 25): Max 18¬∞C / Min 6¬∞C. PARTLY CLOUDY SKY SUSTAINED SURFACE WINDS SPEED REACHING 15-25 KMPH LIKELY MIST DURING NIGHT. Winds: 9.3 km/h WNW. Today. 63¬∞ / 46¬∞. Thunderstorms. 100%. 11 mph ... Showers and thunderstorms. Hazy. High 63F. Winds SSE at 10 to 15 mph. Chance of rain 100%. ... Mostly cloudy skies ... Current Weather Across Delhi - NCR ¬∑ Delhi ¬∑ Gurugram ¬∑ Faridabad ¬∑ Gautam Budh Nagar ¬∑ Ghaziabad. Jahangirpuri. 28.4 ¬∞C; 1.5 km/h; 41.5 %. Mandi Marg. NA ¬∞C Haze today with a high of 65¬∞F and a low of 43¬∞F. Some clouds in the morning will give way to mainly sunny skies for the afternoon. Visibility reduced by smoke. High 64F. Winds W at 5 to 10 mph.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_tool.invoke(\"Weather condition in delhi right now\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "941e567c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def get_weather_data(city: str) -> str:\n",
    "  \"\"\"\n",
    "  This function fetches the current weather data for a given city\n",
    "  \"\"\"\n",
    "  url = f'https://api.weatherstack.com/current?access_key={WEATHERSTACK_API_KEY}&query={city}'\n",
    "\n",
    "  response = requests.get(url)\n",
    "\n",
    "  return str(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2b367985",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_classic.agents import create_react_agent, AgentExecutor\n",
    "from langchain_classic import hub\n",
    "\n",
    "# Fetch a langchain promt from hub\n",
    "promt = hub.pull(\"hwchase17/react\") # reAct agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5e6bee84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ceate a reAct agent\n",
    "agent = create_react_agent(\n",
    "    llm= llm_openai,\n",
    "    tools= [search_tool , get_weather_data],\n",
    "    prompt= promt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cf59d78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an agent executer\n",
    "agent_executer = AgentExecutor(\n",
    "    agent= agent , \n",
    "    tools=[search_tool , get_weather_data],\n",
    "    verbose= True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206dc7f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to find out the home city of Speed, the streamer, and then check the current temperature there. First, I will search for information about Speed's home city.\n",
      "\n",
      "Action: Intermediate_Answer  \n",
      "Action Input: \"What is the home city of Speed the streamer?\"  \u001b[0m\u001b[36;1m\u001b[1;3mWatkins at Chinatown, Singapore, in 2024 ; Born. Darren Jason Watkins Jr. (2005-01-21) January 21, 2005 (age 21). Cincinnati, Ohio, U.S. ; Other names. Speed ... Take a virtual tour of IShowSpeed's lavish $10 million Florida house. This celebrity home showcases luxury and opulence, with stunning features and amenities. üå¥ This impressive residence is available for $15,000 per month and boasts an expansive layout of 4,700 square feet. This is the home of $2 million YouTuber iow speed in Davy Florida and you'll never believe what the $3 million room is hiding. I was today years old when I learned IShowSpeed is from Cincinnati ... I'm not into streaming bros at all, but this crazy mofo shows up in my ... Speed really living his best life. 18 years old, world famous, and has his own house. Couldn't be happier for him. CINCINNATI (WKRC) - Cincinnati-born streamer \"IShowSpeed\" returned to the Queen City for a family reunion and to introduce scores of fans to ... IShowSpeed, whose legal name is Darren Jason Watkins Jr., is one of the most popular streamers around. With more than 41 million YouTube subscribers and 36 ... Take a virtual tour of IShowSpeed's lavish $10 million Florida house. This celebrity home showcases luxury and opulence, with stunning features ... After taking viewers through his old neighborhood, IShowSpeed ventured over to his former high school, Purcell Marian, to visit with some of his ...\u001b[0m\u001b[32;1m\u001b[1;3mI found that Speed, the streamer, is from Cincinnati, Ohio. Now I need to check the current temperature in Cincinnati.\n",
      "\n",
      "Action: get_weather_data  \n",
      "Action Input: \"Cincinnati\"  \u001b[0m\u001b[33;1m\u001b[1;3mb'{\"request\":{\"type\":\"City\",\"query\":\"Cincinnati, United States of America\",\"language\":\"en\",\"unit\":\"m\"},\"location\":{\"name\":\"Cincinnati\",\"country\":\"United States of America\",\"region\":\"Ohio\",\"lat\":\"39.162\",\"lon\":\"-84.457\",\"timezone_id\":\"America\\\\/New_York\",\"localtime\":\"2026-01-25 02:20\",\"localtime_epoch\":1769307600,\"utc_offset\":\"-5.0\"},\"current\":{\"observation_time\":\"07:20 AM\",\"temperature\":-11,\"weather_code\":323,\"weather_icons\":[\"https:\\\\/\\\\/cdn.worldweatheronline.com\\\\/images\\\\/wsymbols01_png_64\\\\/wsymbol_0027_light_snow_showers_night.png\"],\"weather_descriptions\":[\"Light Snow, Mist\"],\"astro\":{\"sunrise\":\"07:50 AM\",\"sunset\":\"05:51 PM\",\"moonrise\":\"11:11 AM\",\"moonset\":\"12:17 AM\",\"moon_phase\":\"Waxing Crescent\",\"moon_illumination\":37},\"air_quality\":{\"co\":\"248.85\",\"no2\":\"14.15\",\"o3\":\"48\",\"so2\":\"6.85\",\"pm2_5\":\"8.75\",\"pm10\":\"9.05\",\"us-epa-index\":\"1\",\"gb-defra-index\":\"1\"},\"wind_speed\":14,\"wind_degree\":64,\"wind_dir\":\"ENE\",\"pressure\":1023,\"precip\":1.1,\"humidity\":88,\"cloudcover\":60,\"feelslike\":-17,\"uv_index\":0,\"visibility\":2,\"is_day\":\"no\"}}'\u001b[0m\u001b[32;1m\u001b[1;3mThe current temperature in Cincinnati is -11¬∞C. Now I can provide the final answer to the question.\n",
      "\n",
      "Final Answer: Speed, the streamer, is from Cincinnati, Ohio, and the current temperature in Cincinnati is -11¬∞C.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': 'What is the Home city of Speed(streamer) and what the temp of that city', 'output': 'Speed, the streamer, is from Cincinnati, Ohio, and the current temperature in Cincinnati is -11¬∞C.'}\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "responce = agent_executer.invoke({\"input\":\"What is the Home city of Speed(streamer) and what the temp of that city\"})\n",
    "print(responce)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7591dae4",
   "metadata": {},
   "source": [
    "#### LangSmith in Langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dab7508d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from typing import TypedDict, Annotated, List\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from langsmith import traceable\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "class EvaluationSchema(BaseModel):\n",
    "    feedback: str = Field(description=\"Detailed feedback for the essay\")\n",
    "    score: int = Field(description=\"Score out of 10\", ge=0, le=10)\n",
    "\n",
    "structured_model = llm_gemini.with_structured_output(EvaluationSchema)\n",
    "\n",
    "essay2 = \"\"\"India and AI Time\n",
    "\n",
    "Now world change very fast because new tech call Artificial Intel‚Ä¶ something (AI). India also want become big in this AI thing. If work hard, India can go top. But if no careful, India go back.\n",
    "\n",
    "India have many good. We have smart student, many engine-ear, and good IT peoples. Big company like TCS, Infosys, Wipro already use AI. Government also do program ‚ÄúAI for All‚Äù. It want AI in farm, doctor place, school and transport.\n",
    "\n",
    "In farm, AI help farmer know when to put seed, when rain come, how stop bug. In health, AI help doctor see sick early. In school, AI help student learn good. Government office use AI to find bad people and work fast.\n",
    "\n",
    "But problem come also. First is many villager no have phone or internet. So AI not help them. Second, many people lose job because AI and machine do work. Poor people get more bad.\n",
    "\n",
    "One more big problem is privacy. AI need big big data. Who take care? India still make data rule. If no strong rule, AI do bad.\n",
    "\n",
    "India must all people together ‚Äì govern, school, company and normal people. We teach AI and make sure AI not bad. Also talk to other country and learn from them.\n",
    "\n",
    "If India use AI good way, we become strong, help poor and make better life. But if only rich use AI, and poor no get, then big bad thing happen.\n",
    "\n",
    "So, in short, AI time in India have many hope and many danger. We must go right road. AI must help all people, not only some. Then India grow big and world say \"good job India\".\n",
    "\"\"\"\n",
    "\n",
    "class UPSCState(TypedDict, total=False):\n",
    "    essay: str\n",
    "    language_feedback: str\n",
    "    analysis_feedback: str\n",
    "    clarity_feedback: str\n",
    "    overall_feedback: str\n",
    "    individual_scores: Annotated[List[int], operator.add]  # merges parallel lists\n",
    "    avg_score: float\n",
    "\n",
    "@traceable(name=\"evaluate_language_fn\", tags=[\"dimension:language\"], metadata={\"dimension\": \"language\"})\n",
    "def evaluate_language(state: UPSCState):\n",
    "    prompt = (\n",
    "        \"Evaluate the language quality of the following essay and provide feedback \"\n",
    "        \"and assign a score out of 10.\\n\\n\" + state[\"essay\"]\n",
    "    )\n",
    "    out = structured_model.invoke(prompt)\n",
    "    return {\"language_feedback\": out.feedback, \"individual_scores\": [out.score]}\n",
    "\n",
    "@traceable(name=\"evaluate_analysis_fn\", tags=[\"dimension:analysis\"], metadata={\"dimension\": \"analysis\"})\n",
    "def evaluate_analysis(state: UPSCState):\n",
    "    prompt = (\n",
    "        \"Evaluate the depth of analysis of the following essay and provide feedback \"\n",
    "        \"and assign a score out of 10.\\n\\n\" + state[\"essay\"]\n",
    "    )\n",
    "    out = structured_model.invoke(prompt)\n",
    "    return {\"analysis_feedback\": out.feedback, \"individual_scores\": [out.score]}\n",
    "\n",
    "@traceable(name=\"evaluate_thought_fn\", tags=[\"dimension:clarity\"], metadata={\"dimension\": \"clarity_of_thought\"})\n",
    "def evaluate_thought(state: UPSCState):\n",
    "    prompt = (\n",
    "        \"Evaluate the clarity of thought of the following essay and provide feedback \"\n",
    "        \"and assign a score out of 10.\\n\\n\" + state[\"essay\"]\n",
    "    )\n",
    "    out = structured_model.invoke(prompt)\n",
    "    return {\"clarity_feedback\": out.feedback, \"individual_scores\": [out.score]}\n",
    "\n",
    "\n",
    "@traceable(name=\"final_evaluation_fn\", tags=[\"aggregate\"])\n",
    "def final_evaluation(state: UPSCState):\n",
    "    prompt = (\n",
    "        \"Based on the following feedback, create a summarized overall feedback.\\n\\n\"\n",
    "        f\"Language feedback: {state.get('language_feedback','')}\\n\"\n",
    "        f\"Depth of analysis feedback: {state.get('analysis_feedback','')}\\n\"\n",
    "        f\"Clarity of thought feedback: {state.get('clarity_feedback','')}\\n\"\n",
    "    )\n",
    "    overall = llm_gemini.invoke(prompt).content\n",
    "    scores = state.get(\"individual_scores\", []) or []\n",
    "    avg = (sum(scores) / len(scores)) if scores else 0.0\n",
    "    return {\"overall_feedback\": overall, \"avg_score\": avg}\n",
    "\n",
    "# ---------- Build graph ----------\n",
    "graph = StateGraph(UPSCState)\n",
    "\n",
    "graph.add_node(\"evaluate_language\", evaluate_language)\n",
    "graph.add_node(\"evaluate_analysis\", evaluate_analysis)\n",
    "graph.add_node(\"evaluate_thought\", evaluate_thought)\n",
    "graph.add_node(\"final_evaluation\", final_evaluation)\n",
    "\n",
    "# Fan-out ‚Üí join\n",
    "graph.add_edge(START, \"evaluate_language\")\n",
    "graph.add_edge(START, \"evaluate_analysis\")\n",
    "graph.add_edge(START, \"evaluate_thought\")\n",
    "graph.add_edge(\"evaluate_language\", \"final_evaluation\")\n",
    "graph.add_edge(\"evaluate_analysis\", \"final_evaluation\")\n",
    "graph.add_edge(\"evaluate_thought\", \"final_evaluation\")\n",
    "graph.add_edge(\"final_evaluation\", END)\n",
    "\n",
    "workflow = graph.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99d670d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Evaluation Results ===\n",
      "Language feedback:\n",
      " The essay demonstrates a basic understanding of the topic but suffers from significant language quality issues. The vocabulary is overly simplistic, and sentence structures are often fragmented or grammatically incorrect (e.g., \"Now world change very fast,\" \"India have many good,\" \"many villager no have phone\"). The use of colloquialisms and informal language is prevalent, detracting from the overall tone and clarity. While the core ideas about India's potential and challenges with AI are present, they are not articulated effectively due to these language limitations. For instance, concepts like \"AI for All\" and the specific applications in farming and healthcare are mentioned but lack detailed explanation or sophisticated phrasing. The essay would greatly benefit from improved grammar, a wider vocabulary, and more complex sentence construction to convey its message more persuasively and professionally. \n",
      "\n",
      "Analysis feedback:\n",
      " The essay touches upon relevant points regarding India's potential in AI, including its strengths (smart students, IT sector, government initiatives) and challenges (digital divide, job displacement, data privacy). However, the analysis lacks depth and critical examination. The language is overly simplistic, and the arguments are presented superficially without sufficient evidence or detailed explanation. For instance, while AI applications in farming, health, and education are mentioned, the essay doesn't delve into the specific mechanisms, scalability, or potential pitfalls of these applications in the Indian context. The discussion on job displacement and privacy is also brief and doesn't explore the nuances of policy, ethical considerations, or potential mitigation strategies. The essay would benefit from a more sophisticated vocabulary, a structured approach, and a deeper exploration of the complexities involved in India's AI journey. \n",
      "\n",
      "Clarity feedback:\n",
      " The essay demonstrates a basic understanding of India's potential in AI, highlighting strengths like a large talent pool and government initiatives. It also touches upon crucial challenges such as the digital divide, job displacement, and data privacy. However, the clarity of thought is hindered by simplistic language, repetitive phrasing, and a lack of specific examples or deeper analysis. The essay would benefit from more sophisticated vocabulary, a clearer structure, and a more nuanced discussion of the complex issues involved. For instance, instead of 'AI Intel... something,' a more precise term like 'Artificial Intelligence' should be used. The essay could also explore the 'AI for All' initiative in more detail, providing examples of its implementation and impact. Similarly, the discussion on job displacement and privacy could be expanded with potential solutions or case studies. The concluding remarks are somewhat repetitive and could be strengthened with a more definitive call to action or a summary of key strategies. \n",
      "\n",
      "Overall feedback:\n",
      " Here's a summarized overall feedback based on the provided comments:\n",
      "\n",
      "**Overall Feedback:**\n",
      "\n",
      "This essay presents a foundational understanding of India's potential and challenges with Artificial Intelligence, touching upon key areas like its strengths (talent pool, IT sector) and crucial concerns (digital divide, job displacement, data privacy). However, the core ideas are significantly hindered by **persistent language quality issues**, including overly simplistic vocabulary, grammatical errors, fragmented sentences, and informal phrasing. These limitations prevent the effective articulation and persuasive presentation of the essay's arguments.\n",
      "\n",
      "Furthermore, the **depth of analysis and clarity of thought are lacking**. While relevant points are raised, they are often presented superficially without sufficient evidence, detailed explanations, or critical examination. The essay would greatly benefit from a more sophisticated vocabulary, complex sentence structures, a structured approach to arguments, and a deeper exploration of the nuances and complexities involved in India's AI journey. Specific examples, precise terminology, and a more detailed discussion of concepts like \"AI for All\" and potential solutions to challenges would significantly enhance the essay's persuasiveness and professionalism. \n",
      "\n",
      "Individual scores: [5, 4, 5]\n",
      "Average score: 4.666666666666667\n"
     ]
    }
   ],
   "source": [
    "result = workflow.invoke(\n",
    "    {\"essay\": essay2},\n",
    "    config={\n",
    "        \"run_name\": \"evaluate_upsc_essay\",  # becomes root run name\n",
    "        \"tags\": [\"essay\", \"langgraph\", \"evaluation\"],\n",
    "        \"metadata\": {\n",
    "            \"essay_length\": len(essay2),\n",
    "            \"model\": \"gpt-4o-mini\",\n",
    "            \"dimensions\": [\"language\", \"analysis\", \"clarity\"],\n",
    "        },\n",
    "    },\n",
    ")\n",
    "\n",
    "print(\"\\n=== Evaluation Results ===\")\n",
    "print(\"Language feedback:\\n\", result.get(\"language_feedback\", \"\"), \"\\n\")\n",
    "print(\"Analysis feedback:\\n\", result.get(\"analysis_feedback\", \"\"), \"\\n\")\n",
    "print(\"Clarity feedback:\\n\", result.get(\"clarity_feedback\", \"\"), \"\\n\")\n",
    "print(\"Overall feedback:\\n\", result.get(\"overall_feedback\", \"\"), \"\\n\")\n",
    "print(\"Individual scores:\", result.get(\"individual_scores\", []))\n",
    "print(\"Average score:\", result.get(\"avg_score\", 0.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ef30eb",
   "metadata": {},
   "source": [
    "##### Features in LangSmith\n",
    "- moniter and alerts\n",
    "- can moniter across traces:\n",
    "- latency, token_usgaes , cost , error_rate , success_rate\n",
    "- Evalution :\n",
    "- test gold-standard dataset, custome metrices like faithfulness, truthfullness\n",
    "\n",
    "- promt experimetation :\n",
    "- test diff experiments A/B testing across promts on same dataset\n",
    "\n",
    "- Dataset creation and annotation \n",
    "- has tool to build dataset, eval and fine-tune\n",
    "- support manual eval\n",
    "\n",
    "- user feedback integration \n",
    "- thumbs up, thumb down rating and structure feedback\n",
    "- can get bulk analysis\n",
    "\n",
    "- collaboration \n",
    "- has sharing, and create shared experiment dashboards\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f26aed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
